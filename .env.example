# BaddyBugs Agent Configuration
# Copy this file to your Laravel .env and configure

# =======================
# Core Configuration
# =======================
BADDYBUGS_ENABLED=true
BADDYBUGS_API_KEY=your-api-key-here
BADDYBUGS_PROJECT_ID=your-project-id-here
BADDYBUGS_ENDPOINT=https://api.baddybugs.io/v1/ingest

# Environment name (production, staging, development, etc.)
APP_ENV=production

# =======================
# Performance Settings
# =======================
# Enable performance mode for high-traffic apps (>1000 req/sec)
BADDYBUGS_PERFORMANCE_MODE=false

# Buffer driver: memory, file, or redis
# - memory: fastest for development
# - file: recommended for production web servers
# - redis: best for high-traffic production
BADDYBUGS_BUFFER_DRIVER=memory

# =======================
# Release Tracking
# =======================
# Set these during deployment for better tracking
BADDYBUGS_RELEASE=v1.0.0
BADDYBUGS_GIT_SHA=abc123def456

# =======================
# Security
# =======================
# Optional: HMAC signing secret for payload integrity
BADDYBUGS_SIGNING_SECRET=

# =======================
# Sampling Rates
# =======================
# Default sampling rate (1.0 = 100%, 0.5 = 50%, etc.)
BADDYBUGS_SAMPLING_RATE=1.0

# =======================
# Frontend Monitoring
# =======================
# Enable frontend monitoring (Blade + Livewire)
BADDYBUGS_FRONTEND_ENABLED=true

# Expose trace_id to frontend via meta tags
BADDYBUGS_EXPOSE_TRACE_ID=true

# Frontend sampling rate (independent from backend)
BADDYBUGS_FRONTEND_SAMPLING_RATE=1.0

# =======================
# Livewire Monitoring
# =======================
# Enable deep Livewire 3 monitoring
# Works automatically with FilamentPHP
BADDYBUGS_LIVEWIRE_MONITORING=true

# Threshold for slow Livewire requests (milliseconds)
# Requests taking longer will be logged as performance issues
BADDYBUGS_LIVEWIRE_TIMEOUT_MS=10000

# Track component initialization events (high volume!)
# Only enable if you need detailed component usage analytics
BADDYBUGS_LIVEWIRE_TRACK_INIT=false

# =======================
# Query Monitoring
# =======================
# Slow query threshold in milliseconds
BADDYBUGS_SLOW_QUERY_THRESHOLD=100

# Detect N+1 query problems
BADDYBUGS_DETECT_N_PLUS_ONE=true

# Run EXPLAIN on slow queries
BADDYBUGS_EXPLAIN_SLOW_QUERIES=true

# =======================
# Redis Buffer Settings
# (Only used when BADDYBUGS_BUFFER_DRIVER=redis)
# =======================
BADDYBUGS_REDIS_CONNECTION=default
BADDYBUGS_REDIS_KEY=baddybugs:buffer
BADDYBUGS_REDIS_MAX_SIZE=10000

# =======================
# Session Replay (Like Highlight.io)
# =======================
# Enable session replay recording
# Records user sessions for debugging production issues
BADDYBUGS_SESSION_REPLAY_ENABLED=false

# Sampling rate (0.0 to 1.0)
# Recommended: 0.01 (1%) for production, 1.0 (100%) for development
# Examples:
#   1.0 = 100% (development)
#   0.1 = 10% (staging)
#   0.01 = 1% (production)
#   0.001 = 0.1% (high-traffic production)
BADDYBUGS_SESSION_REPLAY_SAMPLING_RATE=0.01

# Sampling strategy: 'deterministic' or 'random'
# deterministic = same user always gets same decision (recommended)
# random = each request independently sampled
BADDYBUGS_SESSION_REPLAY_SAMPLING_STRATEGY=deterministic

# Privacy mode: 'strict', 'moderate', or 'none'
# strict = PCI-DSS compliant, masks all inputs (recommended for production)
# moderate = masks only passwords and payment fields
# none = no masking (development only!)
BADDYBUGS_SESSION_REPLAY_PRIVACY=strict

# CSS selectors for elements to completely block from recording
# These elements will appear as blank boxes in the replay
BADDYBUGS_SESSION_REPLAY_BLOCK='.password, [data-private], .credit-card, [type="password"], .ssn, .api-key'

# CSS selectors for text inputs to mask (show as ***)
BADDYBUGS_SESSION_REPLAY_MASK_TEXT='input[type="password"], input[type="email"], .credit-card-number, .cvv'

# Record canvas elements (charts, games, etc.)
# WARNING: Significantly increases replay size
BADDYBUGS_SESSION_REPLAY_RECORD_CANVAS=false

# Record network requests
BADDYBUGS_SESSION_REPLAY_RECORD_NETWORK=true

# Record console logs (errors, warnings, etc.)
BADDYBUGS_SESSION_REPLAY_RECORD_CONSOLE=true

# Record performance metrics (LCP, FCP, etc.)
BADDYBUGS_SESSION_REPLAY_RECORD_PERFORMANCE=true

# Custom session replay endpoint (optional)
# Leave empty to use main endpoint + '/sessions'
BADDYBUGS_SESSION_REPLAY_ENDPOINT=

# =======================
# Regression Risk Analysis
# =======================
# Automatically detect performance degradation after deployments
# Enriches all events with deployment context for pre/post comparison
BADDYBUGS_REGRESSION_ANALYSIS=true

# Deployment hash (commit SHA) - auto-detected from Git if not set
# Set this in your CI/CD pipeline for reliable tracking
# Examples:
#   GitHub Actions: APP_DEPLOYMENT_HASH=${{ github.sha }}
#   GitLab CI: APP_DEPLOYMENT_HASH=$CI_COMMIT_SHA
#   CircleCI: APP_DEPLOYMENT_HASH=$CIRCLE_SHA1
APP_DEPLOYMENT_HASH=

# Deployment tag/version (semantic version recommended)
# Examples: v2.1.0, release-2024-01, staging-abc123
APP_DEPLOYMENT_TAG=

# Deployment metadata (who, when, why)
APP_DEPLOYMENT_RELEASED_BY=
APP_DEPLOYMENT_NOTES=

# Deployment hash source: 'env', 'header', 'git', or 'auto'
# - env: Read from APP_DEPLOYMENT_HASH (recommended for CI/CD)
# - header: Read from X-Deployment-ID request header (canary/blue-green)
# - git: Auto-detect from .git/HEAD (local/staging only)
# - auto: Try env → header → git (in that order)
BADDYBUGS_DEPLOYMENT_HASH_SOURCE=env

# Custom deployment header name (for canary/blue-green deployments)
BADDYBUGS_DEPLOYMENT_HEADER=X-Deployment-ID

# Auto-detect deployment changes
# Automatically triggers deployment_started event when hash changes
BADDYBUGS_AUTO_DETECT_DEPLOYMENT=true

# Tag events with deployment phase (warmup, post_deploy)
BADDYBUGS_TAG_DEPLOYMENT_PHASE=true

# Baseline comparison window (days)
# How many days of historical data to use for regression detection
# 1 = yesterday, 7 = last week (default), 30 = last month
BADDYBUGS_REGRESSION_BASELINE_DAYS=7

# Capture baseline snapshots
# Creates periodic snapshots of metrics for comparison
BADDYBUGS_REGRESSION_CAPTURE_BASELINES=true

# Baseline snapshot interval (requests)
# Take a snapshot every N requests
# Higher = less overhead, lower = more granular detection
BADDYBUGS_REGRESSION_BASELINE_INTERVAL=100

# Deployment warm-up period (minutes)
# Ignore first N minutes after deploy for regression calculation
# Allows caches/connections to warm up
BADDYBUGS_REGRESSION_WARMUP_MINUTES=5
